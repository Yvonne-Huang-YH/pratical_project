{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk.tokenize as tk\n",
    "from rouge_metric import PerlRouge\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_dataset('xsum', split='train')\n",
    "data_test = load_dataset('xsum', split='test')\n",
    "data_valid = load_dataset('xsum', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "except ImportError:\n",
    "    raise ImportError(\"import failure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_gen(tokenizer,model,article,maxlength):\n",
    "    global torch_device \n",
    "    torch_device= torch.device('cuda:0')\n",
    "    model=model.to(torch_device)\n",
    "    article_input_ids = tokenizer.encode_plus(article.replace('\\n',''), return_tensors='pt', max_length=maxlength,truncation=True)['input_ids'].to(torch_device)\n",
    "    summary_ids = model.generate(article_input_ids,num_beams=4,length_penalty=4.0,max_length=maxlength,no_repeat_ngram_size=3)\n",
    "    summary = tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def sum_doc_gen(filestr,n_phrase_para,tokenizer,model):\n",
    "    #load doc and generate original summary\n",
    "    doc=filestr\n",
    "    tokens = tk.sent_tokenize(doc)\n",
    "    sum_ori_doc=sum_gen(tokenizer,model,doc,512)\n",
    "\n",
    "    n_phrase=len(tokens)\n",
    "    n_para=int(n_phrase/n_phrase_para)+1\n",
    "\n",
    "    #divide doc into paragraphs\n",
    "    para=[]\n",
    "    for i in range(n_para):\n",
    "        one_para=\"\"\n",
    "        for j in range(n_phrase_para):\n",
    "            if(i*n_phrase_para+j<n_phrase):\n",
    "                one_para+=tokens[i*n_phrase_para+j]\n",
    "        \n",
    "        para.append(one_para)\n",
    "    #now para[] is a list where each element is one paragraph(one string)\n",
    "\n",
    "    #generate summary for each paragraph\n",
    "    sum_para=[]\n",
    "    for i in range(n_para):\n",
    "        sum_para.append(sum_gen(tokenizer,model,para[i].replace('\\n',''),256))\n",
    "\n",
    "    #change each paragraph for its summary in doc\n",
    "    docs_modified=[]\n",
    "    for i in range(n_para):\n",
    "        one_text=\"\"\n",
    "        for j in range(n_para):\n",
    "            if j==i:\n",
    "                one_text+=sum_para[j]\n",
    "            else:\n",
    "                one_text+=para[j]\n",
    "        docs_modified.append(one_text)\n",
    "\n",
    "    #generate summaries for modified docs\n",
    "    sums_modified=[]\n",
    "    for i in range(n_para):\n",
    "        sums_modified.append(sum_gen(tokenizer,model,docs_modified[i].replace('\\n',''),512))\n",
    "\n",
    "    return sum_ori_doc,n_para,para,sum_para,sums_modified\n",
    "\n",
    "def evaluate(n_para,sum_ori_doc,sums_modified):\n",
    "    rouge = PerlRouge(rouge_n_max=3)\n",
    "\n",
    "    score=0\n",
    "    for i in range(n_para):\n",
    "        scores = rouge.evaluate([sums_modified[i]], [[sum_ori_doc]])\n",
    "        score+=scores['rouge-2']['r']\n",
    "    return score/n_para\n",
    "\n",
    "def evaluate_rouge(sum,ref):\n",
    "    rouge = PerlRouge(rouge_n_max=3)\n",
    "    score = rouge.evaluate([sum],[[ref]])\n",
    "    return score['rouge-2']['r']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntokenizer_pega = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")\\nmodel_pega = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-xsum\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_bart = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model_bart = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "tokenizer_distilbart = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "model_distilbart = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")\n",
    "model_bert = AutoModelForSeq2SeqLM.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")\n",
    "\n",
    "tokenizer_bart_base = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model_bart_base = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "'''\n",
    "tokenizer_pega = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")\n",
    "model_pega = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-xsum\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_my_bart=[]\n",
    "score_rouge_bart=[]\n",
    "for i in range(50):\n",
    "    sum_ori_doc,n_para,para,sum_para,sums_modified=sum_doc_gen(data_test[i]['document'].replace('\\n',''),4,tokenizer_bart,model_bart)\n",
    "    score_my_bart.append(evaluate(n_para,sum_ori_doc,sums_modified))\n",
    "    score_rouge_bart.append(evaluate_rouge(sum_ori_doc,data_test[i]['summary'].replace('\\n','')))\n",
    "\n",
    "score_my_distilbart=[]\n",
    "score_rouge_distilbart=[]\n",
    "for i in range(50):\n",
    "    sum_ori_doc,n_para,para,sum_para,sums_modified=sum_doc_gen(data_test[i]['document'].replace('\\n',''),4,tokenizer_distilbart,model_distilbart)\n",
    "    score_my_distilbart.append(evaluate(n_para,sum_ori_doc,sums_modified))\n",
    "    score_rouge_distilbart.append(evaluate_rouge(sum_ori_doc,data_test[i]['summary'].replace('\\n','')))\n",
    "\n",
    "score_my_bart_base=[]\n",
    "score_rouge_bart_base=[]\n",
    "for i in range(50):\n",
    "    sum_ori_doc,n_para,para,sum_para,sums_modified=sum_doc_gen(data_test[i]['document'].replace('\\n',''),4,tokenizer_bart_base,model_bart_base)\n",
    "    score_my_bart_base.append(evaluate(n_para,sum_ori_doc,sums_modified))\n",
    "    score_rouge_bart_base.append(evaluate_rouge(sum_ori_doc,data_test[i]['summary'].replace('\\n','')))\n",
    "\n",
    "score_my_bert=[]\n",
    "score_rouge_bert=[]\n",
    "for i in range(50):\n",
    "    sum_ori_doc,n_para,para,sum_para,sums_modified=sum_doc_gen(data_test[i]['document'].replace('\\n',''),4,tokenizer_bert,model_bert)\n",
    "    score_my_bert.append(evaluate(n_para,sum_ori_doc,sums_modified))\n",
    "    score_rouge_bert.append(evaluate_rouge(sum_ori_doc,data_test[i]['summary'].replace('\\n','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7901536508730159 0.06358719999999998\n",
      "\n",
      "0.765154726825397 0.06568919999999999\n",
      "\n",
      "0.8305175104761904 0.15791059999999996\n",
      "\n",
      "0.6961957437301588 0.07380739999999998\n"
     ]
    }
   ],
   "source": [
    "print(sum(score_my_bart)/50,sum(score_rouge_bart)/50)\n",
    "print()\n",
    "print(sum(score_my_distilbart)/50,sum(score_rouge_distilbart)/50)\n",
    "print()\n",
    "print(sum(score_my_bart_base)/50,sum(score_rouge_bart_base)/50)\n",
    "print()\n",
    "print(sum(score_my_bert)/50,sum(score_rouge_bert)/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure\n",
    "plt.plot([sum(score_my_bart)/50,sum(score_my_distilbart)/50,sum(score_my_bart_base)/50,sum(score_my_bert)/50],label=\"our method\")\n",
    "plt.plot([sum(score_rouge_bart)/50,sum(score_rouge_distilbart)/50,sum(score_rouge_bart_base)/50,sum(score_rouge_bert)/50],label='ROUGE method')\n",
    "plt.legend()\n",
    "plt.title('comparison')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdfeeecf859d0d7071d76517e8ab0271f2ca3533bb6efdb9085ffaf0b707d158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
